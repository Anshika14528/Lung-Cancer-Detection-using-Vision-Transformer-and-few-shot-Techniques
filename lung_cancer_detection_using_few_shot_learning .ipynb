{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d8b4409a5e304034b973383fa15dd54a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f193ad35add42a3b8105e205788449b",
              "IPY_MODEL_a9f8b0113a6a4e5b92d9c05b9858d6f2",
              "IPY_MODEL_534fcf1066a04999a01680d198a4c1b5"
            ],
            "layout": "IPY_MODEL_8b5ac0d62dd1427f978e4e1c0fe9ba90"
          }
        },
        "6f193ad35add42a3b8105e205788449b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e622fa5dd6244bd7adfc12b835f255ad",
            "placeholder": "​",
            "style": "IPY_MODEL_9d1acdb0f33145ac9d196ad524441f25",
            "value": "model.safetensors: 100%"
          }
        },
        "a9f8b0113a6a4e5b92d9c05b9858d6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4800740c098243b79d93afa3f13ed808",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48ae617bfe6249d185068581ebd3e9ae",
            "value": 346284714
          }
        },
        "534fcf1066a04999a01680d198a4c1b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c323b0d9b70a430787591e9fb2b68bf6",
            "placeholder": "​",
            "style": "IPY_MODEL_bc6b3d20a12741ad9ffb7b5bec0f52d3",
            "value": " 346M/346M [00:01&lt;00:00, 382MB/s]"
          }
        },
        "8b5ac0d62dd1427f978e4e1c0fe9ba90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e622fa5dd6244bd7adfc12b835f255ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d1acdb0f33145ac9d196ad524441f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4800740c098243b79d93afa3f13ed808": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48ae617bfe6249d185068581ebd3e9ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c323b0d9b70a430787591e9fb2b68bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc6b3d20a12741ad9ffb7b5bec0f52d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import timm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ================================\n",
        "#  Device Setup\n",
        "# ================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# ================================\n",
        "#  Data Transformations\n",
        "# ================================\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# ================================\n",
        "#  Load Lung Cancer Dataset\n",
        "# ================================\n",
        "test_dir = r'/content/drive/MyDrive/Data/Val'  # <-- Your validation/test set\n",
        "\n",
        "if not os.path.exists(test_dir):\n",
        "    raise FileNotFoundError(\"Test directory not found. Check the path!\")\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
        "\n",
        "print(\"Class Mapping:\", test_dataset.class_to_idx)  # e.g., {'benign': 0, 'malignant': 1}\n",
        "\n",
        "# ================================\n",
        "#  Define ViT Model for Zero-Shot\n",
        "# ================================\n",
        "class ViTCancerClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ViTCancerClassifier, self).__init__()\n",
        "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "\n",
        "        # Freeze all pretrained ViT layers (zero-shot)\n",
        "        for param in self.vit.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Add classification head (can be optionally trained later)\n",
        "        in_features = self.vit.head.in_features\n",
        "        self.vit.head = nn.Sequential(\n",
        "            nn.Linear(in_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 1)  # Binary classification output\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vit(x)\n",
        "\n",
        "# Initialize model\n",
        "model = ViTCancerClassifier().to(device)\n",
        "\n",
        "# Loss (only used for evaluation)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# ================================\n",
        "#  Evaluation Function (Zero-Shot)\n",
        "# ================================\n",
        "def evaluate(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Zero-Shot Test Loss: {total_loss / len(test_loader):.4f}\")\n",
        "    print(f\"Zero-Shot Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# ================================\n",
        "#  Run Zero-Shot Inference\n",
        "# ================================\n",
        "if __name__ == '__main__':\n",
        "    evaluate(model, test_loader, criterion, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1-yS8OtOrkT",
        "outputId": "2bcc22f9-3e1f-470d-802f-2e9319475c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Class Mapping: {'cancer': 0, 'normal lung tissue': 1}\n",
            "Zero-Shot Test Loss: 0.7056\n",
            "Zero-Shot Test Accuracy: 0.4500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "import timm\n",
        "import random\n",
        "\n",
        "# ================================\n",
        "#  Check Device\n",
        "# ================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# ================================\n",
        "#  Data Preprocessing & Augmentation\n",
        "# ================================\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomAffine(degrees=0, shear=10),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# ================================\n",
        "#  Load Datasets (Check Paths)\n",
        "# ================================\n",
        "train_dir = r'/content/drive/MyDrive/Data/Train'\n",
        "test_dir = r'/content/drive/MyDrive/Data/Val'\n",
        "\n",
        "if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
        "    raise FileNotFoundError(\"Dataset directories not found. Check the paths!\")\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "\n",
        "# One shot learning\n",
        "num_samples = int(0.005 * len(train_dataset))\n",
        "indices = random.sample(range(len(train_dataset)), num_samples)\n",
        "train_subset = Subset(train_dataset, indices)\n",
        "print(num_samples)\n",
        "\n",
        "# Data Loaders\n",
        "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
        "\n",
        "print(\"Class Mapping:\", train_dataset.class_to_idx)\n",
        "\n",
        "# ================================\n",
        "#  Define Pretrained ViT Model for Binary Classification\n",
        "# ================================\n",
        "class ViTCancerClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ViTCancerClassifier, self).__init__()\n",
        "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "        in_features = self.vit.head.in_features\n",
        "        self.vit.head = nn.Sequential(\n",
        "            nn.Linear(in_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vit(x)\n",
        "\n",
        "# Create Model\n",
        "model = ViTCancerClassifier().to(device)\n",
        "\n",
        "# Define Loss and Optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# ================================\n",
        "# Training Loop\n",
        "# ================================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train(model, train_loader, criterion, optimizer, device, epochs=5):\n",
        "    model.train()\n",
        "    epoch_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        epoch_accuracies.append(accuracy)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Evaluation Loop\n",
        "# ================================\n",
        "def evaluate(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    print(f\"Test Loss: {total_loss/len(test_loader):.4f}, Test Accuracy: {correct/total:.4f}\")\n",
        "\n",
        "# ================================\n",
        "#  Run Training & Evaluation\n",
        "# ================================\n",
        "if __name__ == '__main__':\n",
        "    train(model, train_loader, criterion, optimizer, device, epochs=10)\n",
        "    evaluate(model, test_loader, criterion, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426,
          "referenced_widgets": [
            "d8b4409a5e304034b973383fa15dd54a",
            "6f193ad35add42a3b8105e205788449b",
            "a9f8b0113a6a4e5b92d9c05b9858d6f2",
            "534fcf1066a04999a01680d198a4c1b5",
            "8b5ac0d62dd1427f978e4e1c0fe9ba90",
            "e622fa5dd6244bd7adfc12b835f255ad",
            "9d1acdb0f33145ac9d196ad524441f25",
            "4800740c098243b79d93afa3f13ed808",
            "48ae617bfe6249d185068581ebd3e9ae",
            "c323b0d9b70a430787591e9fb2b68bf6",
            "bc6b3d20a12741ad9ffb7b5bec0f52d3"
          ]
        },
        "id": "uDuiNuPCP1tH",
        "outputId": "ac131f5a-8b2d-42fa-f1a1-0ec4b619296c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1\n",
            "Class Mapping: {'cancer': 0, 'normal lung tissue': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8b4409a5e304034b973383fa15dd54a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5984, Accuracy: 1.0000\n",
            "Epoch [2/10], Loss: 0.5494, Accuracy: 1.0000\n",
            "Epoch [3/10], Loss: 0.0558, Accuracy: 1.0000\n",
            "Epoch [4/10], Loss: 0.0251, Accuracy: 1.0000\n",
            "Epoch [5/10], Loss: 0.0178, Accuracy: 1.0000\n",
            "Epoch [6/10], Loss: 0.0013, Accuracy: 1.0000\n",
            "Epoch [7/10], Loss: 0.0011, Accuracy: 1.0000\n",
            "Epoch [8/10], Loss: 0.0006, Accuracy: 1.0000\n",
            "Epoch [9/10], Loss: 0.0038, Accuracy: 1.0000\n",
            "Epoch [10/10], Loss: 0.0004, Accuracy: 1.0000\n",
            "Test Loss: 4.0795, Test Accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "import timm\n",
        "import random\n",
        "\n",
        "# ================================\n",
        "#  Check Device\n",
        "# ================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# ================================\n",
        "#  Data Preprocessing & Augmentation\n",
        "# ================================\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomAffine(degrees=0, shear=10),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# ================================\n",
        "#  Load Datasets (Check Paths)\n",
        "# ================================\n",
        "train_dir = r'/content/drive/MyDrive/Data/Train'\n",
        "test_dir = r'/content/drive/MyDrive/Data/Val'\n",
        "\n",
        "if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
        "    raise FileNotFoundError(\"Dataset directories not found. Check the paths!\")\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "\n",
        "# One shot learning\n",
        "num_samples = int(0.005 * len(train_dataset))\n",
        "indices = random.sample(range(len(train_dataset)), num_samples)\n",
        "train_subset = Subset(train_dataset, indices)\n",
        "print(num_samples)\n",
        "\n",
        "# Data Loaders\n",
        "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
        "\n",
        "print(\"Class Mapping:\", train_dataset.class_to_idx)\n",
        "\n",
        "# ================================\n",
        "#  Define Pretrained ViT Model for Binary Classification\n",
        "# ================================\n",
        "class ViTCancerClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ViTCancerClassifier, self).__init__()\n",
        "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "        in_features = self.vit.head.in_features\n",
        "        self.vit.head = nn.Sequential(\n",
        "            nn.Linear(in_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vit(x)\n",
        "\n",
        "# Create Model\n",
        "model = ViTCancerClassifier().to(device)\n",
        "\n",
        "# Define Loss and Optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# ================================\n",
        "# Training Loop\n",
        "# ================================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train(model, train_loader, criterion, optimizer, device, epochs=5):\n",
        "    model.train()\n",
        "    epoch_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        epoch_accuracies.append(accuracy)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Evaluation Loop\n",
        "# ================================\n",
        "def evaluate(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    print(f\"Test Loss: {total_loss/len(test_loader):.4f}, Test Accuracy: {correct/total:.4f}\")\n",
        "\n",
        "# ================================\n",
        "#  Run Training & Evaluation\n",
        "# ================================\n",
        "if __name__ == '__main__':\n",
        "    train(model, train_loader, criterion, optimizer, device, epochs=5)\n",
        "    evaluate(model, test_loader, criterion, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKzXmetPQMIX",
        "outputId": "8657fd4d-c7be-449e-9adb-80a027bb4178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1\n",
            "Class Mapping: {'cancer': 0, 'normal lung tissue': 1}\n",
            "Epoch [1/5], Loss: 0.5134, Accuracy: 1.0000\n",
            "Epoch [2/5], Loss: 0.1095, Accuracy: 1.0000\n",
            "Epoch [3/5], Loss: 0.0225, Accuracy: 1.0000\n",
            "Epoch [4/5], Loss: 0.0023, Accuracy: 1.0000\n",
            "Epoch [5/5], Loss: 0.0006, Accuracy: 1.0000\n",
            "Test Loss: 3.5978, Test Accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "import timm\n",
        "import random\n",
        "\n",
        "# ================================\n",
        "#  Check Device\n",
        "# ================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# ================================\n",
        "#  Data Preprocessing & Augmentation\n",
        "# ================================\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomAffine(degrees=0, shear=10),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# ================================\n",
        "#  Load Datasets (Check Paths)\n",
        "# ================================\n",
        "train_dir = r'/content/drive/MyDrive/Data/Train'\n",
        "test_dir = r'/content/drive/MyDrive/Data/Val'\n",
        "\n",
        "if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
        "    raise FileNotFoundError(\"Dataset directories not found. Check the paths!\")\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "\n",
        "# Five-shot learning\n",
        "num_samples = int(0.025 * len(train_dataset))\n",
        "indices = random.sample(range(len(train_dataset)), num_samples)\n",
        "train_subset = Subset(train_dataset, indices)\n",
        "print(num_samples)\n",
        "\n",
        "# Data Loaders\n",
        "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
        "\n",
        "print(\"Class Mapping:\", train_dataset.class_to_idx)\n",
        "\n",
        "# ================================\n",
        "#  Define Pretrained ViT Model for Binary Classification\n",
        "# ================================\n",
        "class ViTCancerClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ViTCancerClassifier, self).__init__()\n",
        "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "        in_features = self.vit.head.in_features\n",
        "        self.vit.head = nn.Sequential(\n",
        "            nn.Linear(in_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vit(x)\n",
        "\n",
        "# Create Model\n",
        "model = ViTCancerClassifier().to(device)\n",
        "\n",
        "# Define Loss and Optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# ================================\n",
        "# Training Loop\n",
        "# ================================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train(model, train_loader, criterion, optimizer, device, epochs=5):\n",
        "    model.train()\n",
        "    epoch_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        epoch_accuracies.append(accuracy)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Evaluation Loop\n",
        "# ================================\n",
        "def evaluate(model, test_loader, criterion, device):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            preds = probs > 0.5\n",
        "\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "    print(f\"Test Loss: {total_loss/len(test_loader):.4f}, Test Accuracy: {correct/total:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ================================\n",
        "#  Run Training & Evaluation\n",
        "# ================================\n",
        "if __name__ == '__main__':\n",
        "    train(model, train_loader, criterion, optimizer, device, epochs=5)\n",
        "    evaluate(model, test_loader, criterion, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqG9HBwzRY-U",
        "outputId": "34b4bab6-963a-48a2-d8f9-dbaf0aacb7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "5\n",
            "Class Mapping: {'cancer': 0, 'normal lung tissue': 1}\n",
            "Epoch [1/5], Loss: 0.6532, Accuracy: 1.0000\n",
            "Epoch [2/5], Loss: 0.6362, Accuracy: 0.6000\n",
            "Epoch [3/5], Loss: 0.5275, Accuracy: 0.8000\n",
            "Epoch [4/5], Loss: 0.8813, Accuracy: 0.4000\n",
            "Epoch [5/5], Loss: 0.3645, Accuracy: 0.8000\n",
            "Test Loss: 0.5185, Test Accuracy: 0.5167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "import timm\n",
        "import random\n",
        "\n",
        "# ================================\n",
        "#  Check Device\n",
        "# ================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# ================================\n",
        "#  Data Preprocessing & Augmentation\n",
        "# ================================\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomAffine(degrees=0, shear=10),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# ================================\n",
        "#  Load Datasets (Check Paths)\n",
        "# ================================\n",
        "train_dir = r'/content/drive/MyDrive/Data/Train'\n",
        "test_dir = r'/content/drive/MyDrive/Data/Val'\n",
        "\n",
        "if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
        "    raise FileNotFoundError(\"Dataset directories not found. Check the paths!\")\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "\n",
        "# Reduce training dataset to 5% (Dataset Partioning)\n",
        "\n",
        "num_samples = int(0.05 * len(train_dataset))\n",
        "indices = random.sample(range(len(train_dataset)), num_samples)\n",
        "train_subset = Subset(train_dataset, indices)\n",
        "print(num_samples)\n",
        "\n",
        "# Data Loaders\n",
        "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
        "\n",
        "print(\"Class Mapping:\", train_dataset.class_to_idx)\n",
        "\n",
        "# ================================\n",
        "#  Define Pretrained ViT Model for Binary Classification\n",
        "# ================================\n",
        "class ViTCancerClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ViTCancerClassifier, self).__init__()\n",
        "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "        in_features = self.vit.head.in_features\n",
        "        self.vit.head = nn.Sequential(\n",
        "            nn.Linear(in_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vit(x)\n",
        "\n",
        "# Create Model\n",
        "\n",
        "model = ViTCancerClassifier().to(device)\n",
        "\n",
        "# Define Loss and Optimizer\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Training Loop\n",
        "# ================================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train(model, train_loader, criterion, optimizer, device, epochs=5):\n",
        "    model.train()\n",
        "    epoch_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        epoch_accuracies.append(accuracy)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Evaluation Loop\n",
        "# ================================\n",
        "\n",
        "def evaluate(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    print(f\"Test Loss: {total_loss/len(test_loader):.4f}, Test Accuracy: {correct/total:.4f}\")\n",
        "\n",
        "\n",
        "# ================================\n",
        "#  Run Training & Evaluation\n",
        "# ================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train(model, train_loader, criterion, optimizer, device, epochs=10)\n",
        "    evaluate(model, test_loader, criterion, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBgSVuWXQoYA",
        "outputId": "9ef416fb-32d7-4708-d528-6be2820a07e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "11\n",
            "Class Mapping: {'cancer': 0, 'normal lung tissue': 1}\n",
            "Epoch [1/10], Loss: 0.7906, Accuracy: 0.4545\n",
            "Epoch [2/10], Loss: 0.6261, Accuracy: 0.6364\n",
            "Epoch [3/10], Loss: 0.4557, Accuracy: 0.8182\n",
            "Epoch [4/10], Loss: 0.4897, Accuracy: 0.8182\n",
            "Epoch [5/10], Loss: 0.3140, Accuracy: 0.9091\n",
            "Epoch [6/10], Loss: 0.8181, Accuracy: 0.5455\n",
            "Epoch [7/10], Loss: 0.1895, Accuracy: 1.0000\n",
            "Epoch [8/10], Loss: 0.2130, Accuracy: 0.9091\n",
            "Epoch [9/10], Loss: 0.0996, Accuracy: 1.0000\n",
            "Epoch [10/10], Loss: 0.0208, Accuracy: 1.0000\n",
            "Test Loss: 0.0870, Test Accuracy: 0.9667\n"
          ]
        }
      ]
    }
  ]
}